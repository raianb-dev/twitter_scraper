{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd6cfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs import\n",
    "import requests, json, response\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ee35f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 user     user_id\n",
      "0   {'id': 231579149, 'id_str': '231579149', 'name...   231579149\n",
      "1   {'id': 230186518, 'id_str': '230186518', 'name...   230186518\n",
      "2   {'id': 2203709322, 'id_str': '2203709322', 'na...  2203709322\n",
      "3   {'id': 141817380, 'id_str': '141817380', 'name...   141817380\n",
      "4   {'id': 158487331, 'id_str': '158487331', 'name...   158487331\n",
      "..                                                ...         ...\n",
      "94  {'id': 275220311, 'id_str': '275220311', 'name...   275220311\n",
      "95  {'id': 44627459, 'id_str': '44627459', 'name':...    44627459\n",
      "96  {'id': 280273819, 'id_str': '280273819', 'name...   280273819\n",
      "97  {'id': 4774583973, 'id_str': '4774583973', 'na...  4774583973\n",
      "98  {'id': 29913589, 'id_str': '29913589', 'name':...    29913589\n",
      "\n",
      "[99 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Config of navigation heders requests\n",
    "\n",
    "head = {\n",
    "        'x-guest-token':'1559667199064915968',\n",
    "        'authorization':'Bearer AAAAAAAAAAAAAAAAAAAAANRILgAAAAAAnNwIzUejRCOuH5E6I8xnZz4puTs%3D1Zv7ttfk8LF81IUq16cHjhLTvJu4FA33AGWWjCpTnA'\n",
    "}\n",
    "\n",
    "baseUrl = 'https://twitter.com/i/api/1.1/users/recommendations.json?limit=100'# <-- Config limit of users scraper\n",
    "\n",
    "\n",
    "req = requests.get(baseUrl, headers=head) # Request https\n",
    "req = req.text\n",
    "data = pd.read_json(req)\n",
    "df1 = pd.DataFrame(data) # Creating dataframe\n",
    "print(df1)\n",
    "\n",
    "df1 = df1['user']\n",
    "df1 = pd.DataFrame(list(df1))\n",
    "\n",
    "df1 = df1[[  # Select colluns of table\n",
    "           \n",
    "            'id',\n",
    "            'name',\n",
    "            'screen_name',\n",
    "            'description',\n",
    "            'followers_count',\n",
    "            'friends_count',\n",
    "            'created_at',\n",
    "            'location',\n",
    "            'favourites_count',\n",
    "            'statuses_count',\n",
    "            'url'\n",
    "            \n",
    "        ]]\n",
    "\n",
    "df1 = df1[0:51] # Range of scraper\n",
    "\n",
    "var = df1['id'] \n",
    "users_id = []\n",
    "for i in var:\n",
    "    users_id.append(i) # Define list id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc815090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datecalc: # creating class and function of calculate 'day','month','yaer' diference\n",
    "    \n",
    "    def day_diff(i):\n",
    "        \n",
    "        s = list(df1['created_at'][i].split())\n",
    "        day = s[2]\n",
    "        month = s[1]\n",
    "        year = s[-1]\n",
    "                \n",
    "                            # Treating the format of dates perform the calculations\n",
    "        if month == 'Jan':\n",
    "            month = month.replace('Jan', '01')\n",
    "        elif month == 'Feb':\n",
    "            month = month.replace('Feb','02' )\n",
    "        elif month == 'Mar':\n",
    "            month = month.replace('Mar', '03')\n",
    "        elif month == 'Apr':\n",
    "            month = month.replace('Apr', '04')\n",
    "        elif month == 'May':\n",
    "            month = month.replace('May', '05')\n",
    "        elif month == 'Jun':\n",
    "            month = month.replace('Jun', '06')\n",
    "        elif month == 'Jul':\n",
    "            month = month.replace('Jul', '07')\n",
    "        elif month == 'Aug':\n",
    "            month = month.replace('Aug', '08')\n",
    "        elif month == 'Sep':\n",
    "            month = month.replace('Sep', '09')\n",
    "        elif month == 'Oct':\n",
    "            month = month.replace('Oct', '10')\n",
    "        elif month == 'Nov':\n",
    "            month = month.replace('Nov', '11')\n",
    "        elif month == 'Dec':\n",
    "            month = month.replace('Dec', '12')\n",
    "        \n",
    "        \n",
    "        today = str(date.today())\n",
    "        today = list(today.split('-'))\n",
    "        monthNow = int(today[1])\n",
    "        yearNow = int(today[0])\n",
    "        dayNow = int(today[2])\n",
    "\n",
    "        day = int(day)\n",
    "        month = int(month)\n",
    "        year = int(year)\n",
    "\n",
    "        old_date = datetime(year,month,day)\n",
    "        now_date = datetime(yearNow, monthNow, dayNow)\n",
    "        time_diff = now_date - old_date\n",
    "        time_diff = str(time_diff).split()\n",
    "        time_diff = int(time_diff[0])\n",
    "        return time_diff\n",
    "        \n",
    "     # Calculate mean, median  \n",
    "        \n",
    "        \n",
    "    def week_diff(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        week = (days / 7)\n",
    "        return week\n",
    "        \n",
    "    def month_diff(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        month = (week / 4)\n",
    "        return month\n",
    "    \n",
    "    def mean_day(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        mean_day = (days / 2)\n",
    "        mean_day = round(mean_day, 2)\n",
    "        return mean_day\n",
    "    \n",
    "    def mean_week(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        mean_week = (week / 2)\n",
    "        mean_week = round(mean_week,2)\n",
    "        return mean_week\n",
    "    \n",
    "    def mean_month(i):\n",
    "        month = datecalc.month_diff(x)\n",
    "        mean_month = (month/ 2)\n",
    "        mean_month = round(mean_month, 2)\n",
    "        return mean_month\n",
    "    \n",
    "    def median_day(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        median_day = df1['statuses_count'][x] / days\n",
    "        return median_day\n",
    "    \n",
    "    def median_week(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        median_week = df1['statuses_count'][x] / week\n",
    "        return median_week\n",
    "    \n",
    "    def median_month(i):\n",
    "        month = datecalc.month_diff(x)\n",
    "        median_month = df1['statuses_count'][i] / month\n",
    "        return median_month\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5b81f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping user:0 [231579149, 8563, 3752, 8153, 17.262414685808427, 120.83690280065898, 483.3476112026359, 2124.5, 303.5, 75.88]\n",
      "scraping user:1 [230186518, 9701, 5038, 10035, 1.3625675993416413, 9.537973195391489, 38.151892781565955, 2126.5, 303.79, 75.95]\n",
      "scraping user:2 [2203709322, 9778, 5623, 10716, 23.402882205513784, 163.8201754385965, 655.280701754386, 1596.0, 228.0, 57.0]\n",
      "scraping user:3 [141817380, 11499, 9695, 21018, 11.938643462739849, 83.57050423917893, 334.2820169567157, 2241.0, 320.14, 80.04]\n",
      "scraping user:4 [158487331, 21091, 25518, 41829, 9.514871563767462, 66.60410094637224, 266.41640378548897, 2219.0, 317.0, 79.25]\n",
      "scraping user:5 [8802752, 21143, 25622, 41888, 136.05611589950485, 952.392811296534, 3809.571245186136, 2726.5, 389.5, 97.38]\n",
      "scraping user:6 [2921763658, 51166, 59222, 100071, 11.92648108493933, 83.48536759457531, 333.94147037830123, 1401.0, 200.14, 50.04]\n",
      "scraping user:7 [14128609, 51911, 63006, 106987, 0.11385199240986717, 0.7969639468690701, 3.1878557874762805, 2635.0, 376.43, 94.11]\n",
      "scraping user:8 [228023472, 54880, 67496, 113583, 9.545433200281757, 66.81803240197229, 267.27212960788916, 2129.5, 304.21, 76.05]\n",
      "scraping user:9 [39342378, 55161, 69064, 115839, 4.207017543859649, 29.449122807017545, 117.79649122807018, 2422.5, 346.07, 86.52]\n",
      "scraping user:10 [432983617, 57002, 70490, 142187, 13.08534085084572, 91.59738595592003, 366.3895438236801, 1951.0, 278.71, 69.68]\n",
      "scraping user:11 [128372940, 62024, 85226, 217918, 3.2481751824817517, 22.73722627737226, 90.94890510948905, 2260.5, 322.93, 80.73]\n",
      "scraping user:12 [58603510, 62024, 85226, 228948, 4.102617801047121, 28.718324607329844, 114.87329842931938, 2387.5, 341.07, 85.27]\n",
      "scraping user:13 [2670726740, 74135, 100106, 280963, 8.964370546318289, 62.75059382422803, 251.0023752969121, 1473.5, 210.5, 52.62]\n",
      "scraping user:14 [59591856, 74682, 100993, 285030, 55.6058256496228, 389.24077954735964, 1556.9631181894385, 2386.0, 340.86, 85.21]\n",
      "scraping user:15 [126676337, 75336, 104115, 289721, 4.614891736632789, 32.30424215642952, 129.21696862571807, 2263.0, 323.29, 80.82]\n",
      "scraping user:16 [84730665, 76139, 104948, 296461, 1.6963026287668306, 11.874118401367813, 47.49647360547125, 2339.5, 334.21, 83.55]\n",
      "scraping user:17 [14213711, 76306, 106133, 302398, 16.164542514742248, 113.15179760319575, 452.607190412783, 2628.5, 375.5, 93.88]\n",
      "scraping user:18 [14594813, 76308, 106166, 302423, 113.99367937176785, 797.955755602375, 3191.8230224095, 2610.5, 372.93, 93.23]\n",
      "scraping user:19 [179185127, 76860, 107972, 303469, 15.113620807665983, 105.79534565366188, 423.18138261464753, 2191.5, 313.07, 78.27]\n",
      "scraping user:20 [1203191076066082816, 79125, 108756, 328106, 5.147507629704985, 36.0325534079349, 144.1302136317396, 491.5, 70.21, 17.55]\n",
      "scraping user:21 [1171894501587247104, 79189, 108774, 328170, 15.707476635514018, 109.95233644859813, 439.8093457943925, 535.0, 76.43, 19.11]\n",
      "scraping user:22 [1351188841558913025, 82153, 116738, 338296, 39.17565217391304, 274.2295652173913, 1096.9182608695653, 287.5, 41.07, 10.27]\n",
      "scraping user:23 [226542162, 84201, 118488, 379697, 6.027680037532254, 42.19376026272578, 168.77504105090313, 2131.5, 304.5, 76.12]\n",
      "scraping user:24 [67150902, 84203, 118498, 379701, 92.38419388830347, 646.6893572181243, 2586.7574288724973, 2372.5, 338.93, 84.73]\n",
      "scraping user:25 [941304403054727169, 85062, 118901, 392480, 14.137749120750293, 98.96424384525204, 395.85697538100817, 853.0, 121.86, 30.46]\n",
      "scraping user:26 [9317502, 85089, 118992, 392672, 88.70659786214523, 620.9461850350166, 2483.7847401400663, 2713.0, 387.57, 96.89]\n",
      "scraping user:27 [174226791, 86197, 122886, 396784, 6.098498635122839, 42.689490445859875, 170.7579617834395, 2198.0, 314.0, 78.5]\n",
      "scraping user:28 [54341363, 86215, 122948, 396810, 98.24222175819587, 687.6955523073711, 2750.7822092294846, 2394.5, 342.07, 85.52]\n",
      "scraping user:29 [15292534, 86245, 122980, 396906, 12.863733281643729, 90.04613297150611, 360.18453188602444, 2579.5, 368.5, 92.12]\n",
      "scraping user:30 [283230411, 86310, 123062, 399689, 5.278019323671497, 36.946135265700484, 147.78454106280194, 2070.0, 295.71, 73.93]\n",
      "scraping user:31 [396814767, 86999, 124013, 407331, 7.595189873417722, 53.16632911392404, 212.66531645569617, 1975.0, 282.14, 70.54]\n",
      "scraping user:32 [33804533, 87467, 124345, 408957, 2.9044193216855088, 20.33093525179856, 81.32374100719424, 2432.5, 347.5, 86.88]\n",
      "scraping user:33 [846369751, 87594, 124753, 409558, 7.692691029900332, 53.848837209302324, 215.3953488372093, 1806.0, 258.0, 64.5]\n",
      "scraping user:34 [1113094855281008641, 87796, 127831, 411961, 1.9334415584415585, 13.534090909090908, 54.13636363636363, 616.0, 88.0, 22.0]\n",
      "scraping user:35 [1058748734820044800, 88469, 129642, 413340, 14.591895803183792, 102.14327062228655, 408.5730824891462, 691.0, 98.71, 24.68]\n",
      "scraping user:36 [13769472, 88531, 129998, 414354, 12.8117202268431, 89.68204158790171, 358.72816635160683, 2645.0, 377.86, 94.46]\n",
      "scraping user:37 [41043596, 88548, 130061, 414410, 4.434360140583006, 31.04052098408104, 124.16208393632417, 2418.5, 345.5, 86.38]\n",
      "scraping user:38 [17715048, 88556, 130137, 414439, 70.77041325613895, 495.39289279297265, 1981.5715711718906, 2504.5, 357.79, 89.45]\n",
      "scraping user:39 [28354416, 89728, 131563, 418576, 5.948198198198198, 41.63738738738739, 166.54954954954957, 2442.0, 348.86, 87.21]\n",
      "scraping user:40 [40097683, 89742, 131631, 418583, 8.85233374638579, 61.96633622470054, 247.86534489880216, 2421.0, 345.86, 86.46]\n",
      "scraping user:41 [790680, 89757, 131662, 418629, 47.02901114452503, 329.20307801167525, 1316.812312046701, 2826.5, 403.79, 100.95]\n",
      "scraping user:42 [727130698021261313, 90805, 138768, 441921, 2.91815411406182, 20.42707879843274, 81.70831519373095, 1148.5, 164.07, 41.02]\n",
      "scraping user:43 [801874623176511488, 90821, 138953, 442215, 3.6504065040650406, 25.552845528455283, 102.21138211382113, 1045.5, 149.36, 37.34]\n",
      "scraping user:44 [18297088, 91008, 140154, 443032, 7.220661985957873, 50.54463390170512, 202.17853560682047, 2492.5, 356.07, 89.02]\n",
      "scraping user:45 [10842792, 91038, 140209, 443107, 70.88824734587446, 496.21773142112124, 1984.870925684485, 2684.5, 383.5, 95.88]\n",
      "scraping user:46 [18219976, 91095, 140317, 443297, 47.76768891561435, 334.3738224093005, 1337.495289637202, 2494.5, 356.36, 89.09]\n",
      "scraping user:47 [762402774260875265, 91918, 149898, 450424, 6.471818181818182, 45.302727272727275, 181.2109090909091, 1100.0, 157.14, 39.29]\n",
      "scraping user:48 [290243668, 92155, 150882, 452761, 17.956869396656167, 125.69808577659317, 502.7923431063727, 2063.5, 294.79, 73.7]\n",
      "scraping user:49 [36751573, 92403, 151491, 454791, 3.692339373970346, 25.846375617792425, 103.3855024711697, 2428.0, 346.86, 86.71]\n"
     ]
    }
   ],
   "source": [
    "quote = 0 \n",
    "reply = 0 \n",
    "retweet = 0\n",
    "mean_quote = 0\n",
    "mean_reply = 0\n",
    "mean_tweet = 0\n",
    "users = []\n",
    "\n",
    "\n",
    "# Scraping data from public url allowed by 'Twitter'\n",
    "\n",
    "for x in range(50):\n",
    "    #if x == 40:\n",
    "        #continue    # delete ruids is here \n",
    "\n",
    "    user_id = users_id[x]\n",
    "    url = f'https://twitter.com/i/api/graphql/X0G3yrqmH2bBryO4kPAVMQ/UserTweets?variables=%7B%22userId%22%3A%22{user_id}%22%2C%22count%22%3A60%2C%22includePromotedContent%22%3Atrue%2C%22withQuickPromoteEligibilityTweetFields%22%3Atrue%2C%22withSuperFollowsUserFields%22%3Atrue%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%2C%22withSuperFollowsTweetFields%22%3Atrue%2C%22withVoice%22%3Atrue%2C%22withV2Timeline%22%3Atrue%7D&features=%7B%22dont_mention_me_view_api_enabled%22%3Atrue%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_uc_gql_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%7D'\n",
    "    req = requests.get(url, headers=head)\n",
    "    req = req.text\n",
    "    \n",
    "    # Last 10 tweets from user profile\n",
    "    for i in range(10, 20):\n",
    "\n",
    "        data = json.loads(req)\n",
    "        data = data['data']\n",
    "        data = data['user']\n",
    "        data = data['result']\n",
    "        data = data['timeline_v2']\n",
    "        data = data['timeline']\n",
    "        data = data['instructions'][1]\n",
    "        data = data['entries'][i]\n",
    "        data = data['content']\n",
    "        data = data[\"itemContent\"]\n",
    "        data = data['tweet_results']\n",
    "        data = data['result']\n",
    "        df = pd.DataFrame(data)\n",
    "        df = pd.DataFrame(df['legacy'])\n",
    "        df = df.T # Reverse dataframe\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # Adding quotes within 10 tweets\n",
    "        quote_count = int(df['quote_count'])\n",
    "        quote = quote + quote_count\n",
    "        \n",
    "        # Adding replys within 10 tweets\n",
    "        reply_count = int(df['reply_count'])\n",
    "        reply = reply + reply_count\n",
    "        \n",
    "        # Adding retweet within 10 tweets\n",
    "        retweet_count = int(df['retweet_count'])\n",
    "        retweet = retweet + retweet_count\n",
    "     \n",
    "    # Using the function to calculate the average based on that shaved user profile\n",
    "    median_day = datecalc.median_day(x)\n",
    "    median_week = datecalc.median_week(x)\n",
    "    median_month = datecalc.median_month(x)\n",
    "    \n",
    "    # Using the function to calculate the mean based on that shaved user profile\n",
    "    mean_day = datecalc.mean_day(x)\n",
    "    mean_week = datecalc.mean_week(x)\n",
    "    mean_month = datecalc.mean_month(x)\n",
    "    \n",
    "    \n",
    "    # Adding data to a list\n",
    "    users.append([user_id, quote, reply, retweet, median_day, median_week, median_month, mean_day, mean_week, mean_month])\n",
    "    print(f'scraping user:{x}', users[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31124652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(last_10)\n",
    "\n",
    "# Defining name for shaved columns\n",
    "df2.rename(columns = {\n",
    "                        0:'id', \n",
    "                        1:'quote',\n",
    "                        2:'reply',\n",
    "                        3:'retweet', \n",
    "                        4:'medianDay_tweet', \n",
    "                        5:'medianWeek_tweet', \n",
    "                        6:'medianMonth_tweet',\n",
    "                        7:'meanDay_tweet',\n",
    "                        8:'meanWeek_tweet',\n",
    "                        9:'meanWonth_tweet'}, inplace = True)\n",
    "\n",
    "\n",
    "df = pd.merge(df1, df2, how = 'inner', on = 'id') # Merge between df1 and df2\n",
    "\n",
    "\n",
    "df.to_excel('dataset.xlsx') # Exporting analysis report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dcbe0312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'twitter_scraper'...\n",
      "remote: Enumerating objects: 43, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 43 (delta 14), reused 18 (delta 4), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (43/43), 72.76 KiB | 1.15 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/raianb-dev/twitter_scraper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47db23ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: adding embedded git repository: twitter_scraper\r\n",
      "\u001b[33mhint: You've added another git repository inside your current repository.\u001b[m\r\n",
      "\u001b[33mhint: Clones of the outer repository will not contain the contents of\u001b[m\r\n",
      "\u001b[33mhint: the embedded repository and will not know how to obtain it.\u001b[m\r\n",
      "\u001b[33mhint: If you meant to add a submodule, use:\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: \tgit submodule add <url> twitter_scraper\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: If you added this path by mistake, you can remove it from the\u001b[m\r\n",
      "\u001b[33mhint: index with:\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: \tgit rm --cached twitter_scraper\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: See \"git help submodule\" for more information.\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b dev\n",
    "!git branch\n",
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "caa6f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev 8bd2c25] upload-analys\r\n",
      " 2 files changed, 418 insertions(+), 651 deletions(-)\r\n",
      " rewrite dataset.xlsx (82%)\r\n",
      " rewrite main.ipynb (93%)\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m 'upload-analys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "803c91ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 7, done.\n",
      "Counting objects: 100% (7/7), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (4/4), done.\n",
      "Writing objects: 100% (4/4), 19.06 KiB | 6.35 MiB/s, done.\n",
      "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "remote: This repository moved. Please use the new location:\u001b[K\n",
      "remote:   https://github.com/raianb-dev/twitter_scraper.git\u001b[K\n",
      "To https://github.com/raianb-dev/twtter_minig.git\n",
      "   b822d5f..8bd2c25  dev -> dev\n",
      "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push --set-upstream origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
