{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd6cfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs import\n",
    "import requests, json, response\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee35f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 user              user_id\n",
      "0   {'id': 231579149, 'id_str': '231579149', 'name...            231579149\n",
      "1   {'id': 230186518, 'id_str': '230186518', 'name...            230186518\n",
      "2   {'id': 2203709322, 'id_str': '2203709322', 'na...           2203709322\n",
      "3   {'id': 141817380, 'id_str': '141817380', 'name...            141817380\n",
      "4   {'id': 158487331, 'id_str': '158487331', 'name...            158487331\n",
      "..                                                ...                  ...\n",
      "93  {'id': 51813111, 'id_str': '51813111', 'name':...             51813111\n",
      "94  {'id': 2319390320, 'id_str': '2319390320', 'na...           2319390320\n",
      "95  {'id': 1209790572661268480, 'id_str': '1209790...  1209790572661268480\n",
      "96  {'id': 17877597, 'id_str': '17877597', 'name':...             17877597\n",
      "97  {'id': 35765232, 'id_str': '35765232', 'name':...             35765232\n",
      "\n",
      "[98 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Config of navigation heders requests\n",
    "\n",
    "head = {\n",
    "        'x-guest-token':'1559667199064915968',\n",
    "        'authorization':'Bearer AAAAAAAAAAAAAAAAAAAAANRILgAAAAAAnNwIzUejRCOuH5E6I8xnZz4puTs%3D1Zv7ttfk8LF81IUq16cHjhLTvJu4FA33AGWWjCpTnA'\n",
    "}\n",
    "\n",
    "baseUrl = 'https://twitter.com/i/api/1.1/users/recommendations.json?limit=100'# <-- Config limit of users scraper\n",
    "\n",
    "\n",
    "req = requests.get(baseUrl, headers=head) # Request https\n",
    "req = req.text\n",
    "data = pd.read_json(req)\n",
    "df1 = pd.DataFrame(data) # Creating dataframe\n",
    "print(df1)\n",
    "\n",
    "df1 = df1['user']\n",
    "df1 = pd.DataFrame(list(df1))\n",
    "\n",
    "df1 = df1[[  # Select colluns of table\n",
    "           \n",
    "            'id',\n",
    "            'name',\n",
    "            'screen_name',\n",
    "            'description',\n",
    "            'followers_count',\n",
    "            'friends_count',\n",
    "            'created_at',\n",
    "            'location',\n",
    "            'favourites_count',\n",
    "            'statuses_count',\n",
    "            'url'\n",
    "            \n",
    "        ]]\n",
    "\n",
    "df1 = df1[0:60] # Range of scraper\n",
    "\n",
    "var = df1['id'] \n",
    "users_id = []\n",
    "for i in var:\n",
    "    users_id.append(i) # Define list id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc815090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datecalc: # creating class and function of calculate 'day','month','yaer' diference\n",
    "    \n",
    "    def day_diff(i):\n",
    "        \n",
    "        s = list(df1['created_at'][i].split())\n",
    "        day = s[2]\n",
    "        month = s[1]\n",
    "        year = s[-1]\n",
    "                \n",
    "                            # Treating the format of dates perform the calculations\n",
    "        if month == 'Jan':\n",
    "            month = month.replace('Jan', '01')\n",
    "        elif month == 'Feb':\n",
    "            month = month.replace('Feb','02' )\n",
    "        elif month == 'Mar':\n",
    "            month = month.replace('Mar', '03')\n",
    "        elif month == 'Apr':\n",
    "            month = month.replace('Apr', '04')\n",
    "        elif month == 'May':\n",
    "            month = month.replace('May', '05')\n",
    "        elif month == 'Jun':\n",
    "            month = month.replace('Jun', '06')\n",
    "        elif month == 'Jul':\n",
    "            month = month.replace('Jul', '07')\n",
    "        elif month == 'Aug':\n",
    "            month = month.replace('Aug', '08')\n",
    "        elif month == 'Sep':\n",
    "            month = month.replace('Sep', '09')\n",
    "        elif month == 'Oct':\n",
    "            month = month.replace('Oct', '10')\n",
    "        elif month == 'Nov':\n",
    "            month = month.replace('Nov', '11')\n",
    "        elif month == 'Dec':\n",
    "            month = month.replace('Dec', '12')\n",
    "        \n",
    "        \n",
    "        today = str(date.today())\n",
    "        today = list(today.split('-'))\n",
    "        monthNow = int(today[1])\n",
    "        yearNow = int(today[0])\n",
    "        dayNow = int(today[2])\n",
    "\n",
    "        day = int(day)\n",
    "        month = int(month)\n",
    "        year = int(year)\n",
    "\n",
    "        old_date = datetime(year,month,day)\n",
    "        now_date = datetime(yearNow, monthNow, dayNow)\n",
    "        time_diff = now_date - old_date\n",
    "        time_diff = str(time_diff).split()\n",
    "        time_diff = int(time_diff[0])\n",
    "        return time_diff\n",
    "        \n",
    "     # Calculate mean, median  \n",
    "        \n",
    "        \n",
    "    def week_diff(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        week = (days / 7)\n",
    "        return week\n",
    "        \n",
    "    def month_diff(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        month = (week / 4)\n",
    "        return month\n",
    "    \n",
    "    def mean_day(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        mean_day = (days / 2)\n",
    "        mean_day = round(mean_day, 2)\n",
    "        return mean_day\n",
    "    \n",
    "    def mean_week(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        mean_week = (week / 2)\n",
    "        mean_week = round(mean_week,2)\n",
    "        return mean_week\n",
    "    \n",
    "    def mean_month(i):\n",
    "        month = datecalc.month_diff(x)\n",
    "        mean_month = (month/ 2)\n",
    "        mean_month = round(mean_month, 2)\n",
    "        return mean_month\n",
    "    \n",
    "    def median_day(i):\n",
    "        days = datecalc.day_diff(x)\n",
    "        median_day = df1['statuses_count'][x] / days\n",
    "        return median_day\n",
    "    \n",
    "    def median_week(i):\n",
    "        week = datecalc.week_diff(x)\n",
    "        median_week = df1['statuses_count'][x] / week\n",
    "        return median_week\n",
    "    \n",
    "    def median_month(i):\n",
    "        month = datecalc.month_diff(x)\n",
    "        median_month = df1['statuses_count'][i] / month\n",
    "        return median_month\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b81f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping user:0 [231579149, 8588, 3764, 8176, 17.262414685808427, 120.83690280065898, 483.3476112026359, 2124.5, 303.5, 75.88]\n",
      "scraping user:1 [230186518, 9726, 5050, 10060, 1.3625675993416413, 9.537973195391489, 38.151892781565955, 2126.5, 303.79, 75.95]\n",
      "scraping user:2 [2203709322, 9803, 5635, 10741, 23.402882205513784, 163.8201754385965, 655.280701754386, 1596.0, 228.0, 57.0]\n",
      "scraping user:3 [141817380, 11525, 9707, 21045, 11.938643462739849, 83.57050423917893, 334.2820169567157, 2241.0, 320.14, 80.04]\n",
      "scraping user:4 [158487331, 21117, 25529, 41857, 9.514871563767462, 66.60410094637224, 266.41640378548897, 2219.0, 317.0, 79.25]\n",
      "scraping user:5 [8802752, 21134, 25642, 41933, 136.05813313772236, 952.4069319640565, 3809.627727856226, 2726.5, 389.5, 97.38]\n",
      "scraping user:6 [2921763658, 51157, 59241, 100113, 11.92648108493933, 83.48536759457531, 333.94147037830123, 1401.0, 200.14, 50.04]\n",
      "scraping user:7 [14128609, 51903, 63026, 107029, 0.11385199240986717, 0.7969639468690701, 3.1878557874762805, 2635.0, 376.43, 94.11]\n",
      "scraping user:8 [228023472, 54869, 67516, 113625, 9.545433200281757, 66.81803240197229, 267.27212960788916, 2129.5, 304.21, 76.05]\n",
      "scraping user:9 [39342378, 55150, 69084, 115881, 4.207017543859649, 29.449122807017545, 117.79649122807018, 2422.5, 346.07, 86.52]\n",
      "scraping user:10 [432983617, 56993, 70511, 142237, 13.08534085084572, 91.59738595592003, 366.3895438236801, 1951.0, 278.71, 69.68]\n",
      "scraping user:11 [128372940, 62268, 90718, 217697, 3.2488387524883877, 22.741871267418713, 90.96748506967485, 2260.5, 322.93, 80.73]\n",
      "scraping user:12 [58603510, 62268, 90718, 228727, 4.102617801047121, 28.718324607329844, 114.87329842931938, 2387.5, 341.07, 85.27]\n",
      "scraping user:13 [2670726740, 74727, 105846, 283087, 8.964709874448591, 62.75296912114014, 251.01187648456056, 1473.5, 210.5, 52.62]\n",
      "scraping user:14 [59591856, 75281, 106751, 287244, 55.6058256496228, 389.24077954735964, 1556.9631181894385, 2386.0, 340.86, 85.21]\n",
      "scraping user:15 [126676337, 75935, 109873, 291933, 4.614891736632789, 32.30424215642952, 129.21696862571807, 2263.0, 323.29, 80.82]\n",
      "scraping user:16 [84730665, 76738, 110706, 298672, 1.6963026287668306, 11.874118401367813, 47.49647360547125, 2339.5, 334.21, 83.55]\n",
      "scraping user:17 [14213711, 76906, 111891, 304611, 16.164542514742248, 113.15179760319575, 452.607190412783, 2628.5, 375.5, 93.88]\n",
      "scraping user:18 [14594813, 76920, 111979, 304651, 113.99655238460065, 797.9758666922045, 3191.903466768818, 2610.5, 372.93, 93.23]\n",
      "scraping user:19 [179185127, 77472, 113785, 305697, 15.113620807665983, 105.79534565366188, 423.18138261464753, 2191.5, 313.07, 78.27]\n",
      "scraping user:20 [1203191076066082816, 79739, 114569, 330341, 5.14852492370295, 36.039674465920655, 144.15869786368262, 491.5, 70.21, 17.55]\n",
      "scraping user:21 [1171894501587247104, 79812, 114587, 330405, 15.707476635514018, 109.95233644859813, 439.8093457943925, 535.0, 76.43, 19.11]\n",
      "scraping user:22 [1351188841558913025, 82776, 122551, 340531, 39.17565217391304, 274.2295652173913, 1096.9182608695653, 287.5, 41.07, 10.27]\n",
      "scraping user:23 [226542162, 84824, 124301, 381930, 6.027680037532254, 42.19376026272578, 168.77504105090313, 2131.5, 304.5, 76.12]\n",
      "scraping user:24 [67150902, 84824, 124304, 381933, 92.38566912539515, 646.699683877766, 2586.798735511064, 2372.5, 338.93, 84.73]\n",
      "scraping user:25 [941304403054727169, 85683, 124707, 394712, 14.137162954279015, 98.9601406799531, 395.8405627198124, 853.0, 121.86, 30.46]\n",
      "scraping user:26 [9317502, 85696, 124774, 394762, 88.70991522300037, 620.9694065610026, 2483.8776262440106, 2713.0, 387.57, 96.89]\n",
      "scraping user:27 [174226791, 86804, 128668, 398873, 6.098498635122839, 42.689490445859875, 170.7579617834395, 2198.0, 314.0, 78.5]\n",
      "scraping user:28 [54341363, 86846, 128746, 398919, 98.24493631238255, 687.7145541866778, 2750.858216746711, 2394.5, 342.07, 85.52]\n",
      "scraping user:29 [15292534, 86878, 128779, 399032, 12.864120953673192, 90.04884667571234, 360.19538670284936, 2579.5, 368.5, 92.12]\n",
      "scraping user:30 [283230411, 86943, 128880, 401825, 5.278260869565218, 36.94782608695652, 147.79130434782607, 2070.0, 295.71, 73.93]\n",
      "scraping user:31 [396814767, 87636, 129831, 409486, 7.595189873417722, 53.16632911392404, 212.66531645569617, 1975.0, 282.14, 70.54]\n",
      "scraping user:32 [33804533, 88104, 130163, 411113, 2.9046248715313463, 20.332374100719424, 81.3294964028777, 2432.5, 347.5, 86.88]\n",
      "scraping user:33 [846369751, 88286, 130799, 412066, 7.693244739756367, 53.85271317829457, 215.4108527131783, 1806.0, 258.0, 64.5]\n",
      "scraping user:34 [142393421, 88294, 130924, 412103, 35.04619504574872, 245.32336532024104, 981.2934612809642, 2240.5, 320.07, 80.02]\n",
      "scraping user:35 [1113094855281008641, 88496, 134002, 414507, 1.9334415584415585, 13.534090909090908, 54.13636363636363, 616.0, 88.0, 22.0]\n",
      "scraping user:36 [1058748734820044800, 89169, 135813, 415886, 14.591895803183792, 102.14327062228655, 408.5730824891462, 691.0, 98.71, 24.68]\n",
      "scraping user:37 [13769472, 89231, 136169, 416900, 12.8117202268431, 89.68204158790171, 358.72816635160683, 2645.0, 377.86, 94.46]\n",
      "scraping user:38 [41043596, 89248, 136232, 416956, 4.434360140583006, 31.04052098408104, 124.16208393632417, 2418.5, 345.5, 86.38]\n",
      "scraping user:39 [17715048, 89255, 136319, 416981, 70.7718107406668, 495.4026751846676, 1981.6107007386704, 2504.5, 357.79, 89.45]\n",
      "scraping user:40 [28354416, 90426, 137745, 421118, 5.948198198198198, 41.63738738738739, 166.54954954954957, 2442.0, 348.86, 87.21]\n",
      "scraping user:41 [40097683, 90440, 137813, 421125, 8.85233374638579, 61.96633622470054, 247.86534489880216, 2421.0, 345.86, 86.46]\n",
      "scraping user:42 [790680, 90453, 137841, 421169, 47.029541836193175, 329.2067928533522, 1316.827171413409, 2826.5, 403.79, 100.95]\n",
      "scraping user:43 [3331429624, 90551, 137978, 421266, 86.06687046236148, 602.4680932365304, 2409.8723729461217, 1308.5, 186.93, 46.73]\n",
      "scraping user:44 [727130698021261313, 91599, 145085, 444552, 2.91815411406182, 20.42707879843274, 81.70831519373095, 1148.5, 164.07, 41.02]\n",
      "scraping user:45 [801874623176511488, 91615, 145270, 444846, 3.6504065040650406, 25.552845528455283, 102.21138211382113, 1045.5, 149.36, 37.34]\n",
      "scraping user:46 [18297088, 91802, 146471, 445663, 7.220661985957873, 50.54463390170512, 202.17853560682047, 2492.5, 356.07, 89.02]\n",
      "scraping user:47 [10842792, 91826, 146512, 445721, 70.8888061091451, 496.22164276401566, 1984.8865710560626, 2684.5, 383.5, 95.88]\n",
      "scraping user:48 [18219976, 91933, 146652, 446005, 47.76849067949489, 334.37943475646426, 1337.517739025857, 2494.5, 356.36, 89.09]\n",
      "scraping user:49 [762402774260875265, 92760, 156344, 453161, 6.471818181818182, 45.302727272727275, 181.2109090909091, 1100.0, 157.14, 39.29]\n",
      "scraping user:50 [290243668, 92997, 157328, 455499, 17.956869396656167, 125.69808577659317, 502.7923431063727, 2063.5, 294.79, 73.7]\n",
      "scraping user:51 [809124436880322561, 93004, 157382, 455519, 59.0338000965717, 413.23660067600196, 1652.9464027040078, 1035.5, 147.93, 36.98]\n",
      "scraping user:52 [36751573, 93252, 157991, 457549, 3.692339373970346, 25.846375617792425, 103.3855024711697, 2428.0, 346.86, 86.71]\n",
      "scraping user:53 [354095556, 93373, 159533, 466095, 1.706291967172345, 11.944043770206417, 47.776175080825666, 2010.5, 287.21, 71.8]\n",
      "scraping user:54 [1095834875716874245, 93392, 159890, 466548, 1.7578125, 12.3046875, 49.21875, 640.0, 91.43, 22.86]\n",
      "scraping user:55 [14594698, 93443, 160037, 466588, 105.6075464470408, 739.2528251292855, 2957.011300517142, 2610.5, 372.93, 93.23]\n",
      "scraping user:56 [68313718, 93464, 160743, 466645, 5.059071729957806, 35.413502109704645, 141.65400843881858, 2370.0, 338.57, 84.64]\n",
      "scraping user:57 [135743827, 93561, 161512, 467964, 2.9735496777061567, 20.8148477439431, 83.2593909757724, 2249.5, 321.36, 80.34]\n",
      "scraping user:58 [56079927, 93670, 162132, 471236, 2.8783190466234583, 20.148233326364206, 80.59293330545682, 2391.5, 341.64, 85.41]\n",
      "scraping user:59 [70577513, 94806, 163716, 472994, 4.889475908706678, 34.226331360946745, 136.90532544378698, 2366.0, 338.0, 84.5]\n"
     ]
    }
   ],
   "source": [
    "quote = 0 \n",
    "reply = 0 \n",
    "retweet = 0\n",
    "mean_quote = 0\n",
    "mean_reply = 0\n",
    "mean_tweet = 0\n",
    "users = []\n",
    "\n",
    "\n",
    "# Scraping data from public url allowed by 'Twitter'\n",
    "\n",
    "for x in range(60): # using range 60 to avoid noise\n",
    "    #if x == 40:\n",
    "        #continue    # delete ruids is here \n",
    "\n",
    "    user_id = users_id[x]\n",
    "    url = f'https://twitter.com/i/api/graphql/X0G3yrqmH2bBryO4kPAVMQ/UserTweets?variables=%7B%22userId%22%3A%22{user_id}%22%2C%22count%22%3A60%2C%22includePromotedContent%22%3Atrue%2C%22withQuickPromoteEligibilityTweetFields%22%3Atrue%2C%22withSuperFollowsUserFields%22%3Atrue%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%2C%22withSuperFollowsTweetFields%22%3Atrue%2C%22withVoice%22%3Atrue%2C%22withV2Timeline%22%3Atrue%7D&features=%7B%22dont_mention_me_view_api_enabled%22%3Atrue%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_uc_gql_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%7D'\n",
    "    req = requests.get(url, headers=head)\n",
    "    req = req.text\n",
    "    \n",
    "    # Last 10 tweets from user profile\n",
    "    for i in range(10, 20):\n",
    "\n",
    "        data = json.loads(req)\n",
    "        data = data['data']\n",
    "        data = data['user']\n",
    "        data = data['result']\n",
    "        data = data['timeline_v2']\n",
    "        data = data['timeline']\n",
    "        data = data['instructions'][1]\n",
    "        data = data['entries'][i]\n",
    "        data = data['content']\n",
    "        data = data[\"itemContent\"]\n",
    "        data = data['tweet_results']\n",
    "        data = data['result']\n",
    "        df = pd.DataFrame(data)\n",
    "        df = pd.DataFrame(df['legacy'])\n",
    "        df = df.T # Reverse dataframe\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # Adding quotes within 10 tweets\n",
    "        quote_count = int(df['quote_count'])\n",
    "        quote = quote + quote_count\n",
    "        \n",
    "        # Adding replys within 10 tweets\n",
    "        reply_count = int(df['reply_count'])\n",
    "        reply = reply + reply_count\n",
    "        \n",
    "        # Adding retweet within 10 tweets\n",
    "        retweet_count = int(df['retweet_count'])\n",
    "        retweet = retweet + retweet_count\n",
    "     \n",
    "    # Using the function to calculate the average based on that shaved user profile\n",
    "    median_day = datecalc.median_day(x)\n",
    "    median_week = datecalc.median_week(x)\n",
    "    median_month = datecalc.median_month(x)\n",
    "    \n",
    "    # Using the function to calculate the mean based on that shaved user profile\n",
    "    mean_day = datecalc.mean_day(x)\n",
    "    mean_week = datecalc.mean_week(x)\n",
    "    mean_month = datecalc.mean_month(x)\n",
    "    \n",
    "    \n",
    "    # Adding data to a list\n",
    "    users.append([user_id, quote, reply, retweet, median_day, median_week, median_month, mean_day, mean_week, mean_month])\n",
    "    print(f'scraping user:{x}', users[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31124652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(users)\n",
    "\n",
    "# Defining name for shaved columns\n",
    "df2.rename(columns = {\n",
    "                        0:'id', \n",
    "                        1:'quote',\n",
    "                        2:'reply',\n",
    "                        3:'retweet', \n",
    "                        4:'medianDay_tweet', \n",
    "                        5:'medianWeek_tweet', \n",
    "                        6:'medianMonth_tweet',\n",
    "                        7:'meanDay_tweet',\n",
    "                        8:'meanWeek_tweet',\n",
    "                        9:'meanWonth_tweet'}, inplace = True)\n",
    "\n",
    "\n",
    "df = pd.merge(df1, df2, how = 'inner', on = 'id') # Merge between df1 and df2\n",
    "df = df[0:50] # using range 50 set in test\n",
    "\n",
    "df.to_excel('dataset.xlsx') # Exporting analysis report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47db23ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'dev'\r\n",
      "Your branch and 'origin/dev' have diverged,\r\n",
      "and have 3 and 6 different commits each, respectively.\r\n",
      "  (use \"git pull\" to merge the remote branch into yours)\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caa6f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\r\n",
      "Your branch and 'origin/dev' have diverged,\r\n",
      "and have 3 and 6 different commits each, respectively.\r\n",
      "  (use \"git pull\" to merge the remote branch into yours)\r\n",
      "\r\n",
      "nothing to commit, working tree clean\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "803c91ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 8 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), 2.53 KiB | 259.00 KiB/s, done.\n",
      "From https://github.com/raianb-dev/twitter_scraper\n",
      " * branch            dev        -> FETCH_HEAD\n",
      "   864571d..69eb3b6  dev        -> origin/dev\n",
      "\u001b[33mhint: Pulling without specifying how to reconcile divergent branches is\u001b[m\n",
      "\u001b[33mhint: discouraged. You can squelch this message by running one of the following\u001b[m\n",
      "\u001b[33mhint: commands sometime before your next pull:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint:   git config pull.rebase false  # merge (the default strategy)\u001b[m\n",
      "\u001b[33mhint:   git config pull.rebase true   # rebase\u001b[m\n",
      "\u001b[33mhint:   git config pull.ff only       # fast-forward only\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: You can replace \"git config\" with \"git config --global\" to set a default\u001b[m\n",
      "\u001b[33mhint: preference for all repositories. You can also pass --rebase, --no-rebase,\u001b[m\n",
      "\u001b[33mhint: or --ff-only on the command line to override the configured default per\u001b[m\n",
      "\u001b[33mhint: invocation.\u001b[m\n",
      "hint: Waiting for your editor to close the file... \u001b7\u001b[?47h\u001b[>4;2m\u001b[?1h\u001b=\u001b[?2004h\u001b[?1004h\u001b[1;24r\u001b[?12h\u001b[?12l\u001b[22;2t\u001b[22;1t\u001b[29m\u001b[m\u001b[H\u001b[2J\u001b[?25l\u001b[24;1H\"~/Documents/py_test/twitter_scraper/.git/MERGE_MSG\" 6L, 303B\u001b[2;1Hâ–½\u001b[6n\u001b[2;1H  \u001b[3;1H\u001bPzz\u001b\\\u001b[0%m\u001b[6n\u001b[3;1H           \u001b[1;1H\u001b[>c\u001b]10;?\u0007\u001b]11;?\u0007\u001b[1;1HMerge branch 'dev' of https://github.com/raianb-dev/twitter_scraper into dev\n",
      "# Please enter a commit message to explain why this merge is necessary,\u001b[2;72H\u001b[K\u001b[3;1H# especially if it merges an updated upstream into a topic branch.\u001b[3;67H\u001b[K\u001b[4;1H#\n",
      "# Lines starting with '#' will be ignored, and an empty message aborts\n",
      "# the commit.\n",
      "\u001b[1m\u001b[34m~                                                                               \u001b[8;1H~                                                                               \u001b[9;1H~                                                                               \u001b[10;1H~                                                                               \u001b[11;1H~                                                                               \u001b[12;1H~                                                                               \u001b[13;1H~                                                                               \u001b[14;1H~                                                                               \u001b[15;1H~                                                                               \u001b[16;1H~                                                                               \u001b[17;1H~                                                                               \u001b[18;1H~                                                                               \u001b[19;1H~                                                                               \u001b[20;1H~                                                                               \u001b[21;1H~                                                                               \u001b[22;1H~                                                                               \u001b[23;1H~                                                                               \u001b[1;1H\u001b[?25h\u001b[?25l\u001b[m\u001b[24;1HType  :qa  and press <Enter> to exit Vim\u001b[24;41H\u001b[K\u0007\u001b[1;1H\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!git pull --set-upstream origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
